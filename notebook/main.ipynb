{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/competitions/playground-series-s6e1/data?select=train.csv\n",
    "\n",
    "# 1. Load the datasets\n",
    "folder_path_local = \"../input/playground-series-s6e1/\"\n",
    "folder_path_remote = \"https://kagglecsv.netlify.app/input/playground-series-s6e1/\"\n",
    "folder_path = folder_path_local if os.path.exists(folder_path_local) else folder_path_remote  # choose local if available, else remote\n",
    "train_data = pd.read_csv(folder_path + 'train.csv')\n",
    "test_data = pd.read_csv(folder_path + 'test.csv')\n",
    "print(\"Datasets loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Columns: Index(['id', 'age', 'gender', 'course', 'study_hours', 'class_attendance',\n",
      "       'internet_access', 'sleep_hours', 'sleep_quality', 'study_method',\n",
      "       'facility_rating', 'exam_difficulty', 'exam_score'],\n",
      "      dtype='object')\n",
      "Test Data Columns: Index(['id', 'age', 'gender', 'course', 'study_hours', 'class_attendance',\n",
      "       'internet_access', 'sleep_hours', 'sleep_quality', 'study_method',\n",
      "       'facility_rating', 'exam_difficulty'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 2. Check column names for both train and test data\n",
    "print(\"Train Data Columns:\", train_data.columns)\n",
    "print(\"Test Data Columns:\", test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: Index(['gender', 'course', 'internet_access', 'sleep_quality', 'study_method',\n",
      "       'facility_rating', 'exam_difficulty'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 3. Identify categorical columns (ignore 'id' column)\n",
    "categorical_columns = train_data.select_dtypes(include=['object']).columns\n",
    "categorical_columns = categorical_columns.drop('id', errors='ignore')  # Drop 'id' if it exists, otherwise ignore\n",
    "print(f\"Categorical columns: {categorical_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features encoded successfully.\n"
     ]
    }
   ],
   "source": [
    "# 4. Label Encoding for categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder to each categorical column\n",
    "for col in categorical_columns:\n",
    "    train_data[col] = label_encoder.fit_transform(train_data[col])\n",
    "    test_data[col] = label_encoder.transform(test_data[col])  # Ensure the test data is encoded the same way\n",
    "\n",
    "print(\"Categorical features encoded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Split data into features (X) and target (y)\n",
    "if 'id' in train_data.columns:  # Check if 'id' exists before dropping it\n",
    "    X = train_data.drop(columns=['id', 'exam_score'])  # Drop 'id' and 'exam_score' columns\n",
    "else:\n",
    "    X = train_data.drop(columns=['exam_score'])  # Only drop 'exam_score' if 'id' is not present\n",
    "y = train_data['exam_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Feature Scaling (Standardizing the features)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Train-test split (for evaluation purposes)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2026-01-01T00:41:09.667621Z",
     "shell.execute_reply": "2026-01-01T00:41:09.666559Z",
     "shell.execute_reply.started": "2026-01-01T00:29:45.489881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression , Ridge, Lasso, ElasticNet, BayesianRidge\n",
    "# from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "# from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tensorflow.keras import Model\n",
    "# from tensorflow.keras.layers import Input, Dense, LSTM, GRU, Conv1D, MaxPooling1D, Flatten, MultiHeadAttention, LayerNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# 8. initialize models\n",
    "\n",
    "# Define XGBoost parameters\n",
    "# xgb_params = { # 8.792066858871292 if 1000\n",
    "#     'n_estimators': 10000,\n",
    "#     'learning_rate': 0.007,\n",
    "#     'max_depth': 7,\n",
    "#     'subsample': 0.8,\n",
    "#     'reg_lambda': 3,\n",
    "#     'colsample_bytree': 0.6,\n",
    "#     'colsample_bynode': 0.7,\n",
    "#     'tree_method': 'hist',\n",
    "#     'random_state': 42,\n",
    "#     'early_stopping_rounds': 100,\n",
    "#     'eval_metric': 'rmse',\n",
    "#     'enable_categorical': True\n",
    "# }\n",
    "\n",
    "# Use actual feature count for Keras model input dimension\n",
    "num_features = X_scaled.shape[1]\n",
    "\n",
    "models = {\n",
    "    # Scikit-learn models\n",
    "    # \"Linear Regression\": LinearRegression(), # 9.945236827130886\n",
    "    # \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=42), # 9.119773196172922\n",
    "    # \"Gradient Boosting Regressor\": GradientBoostingRegressor(n_estimators=100, random_state=42), # 8.853389182802118\n",
    "    # \"Support Vector Regressor (SVR)\": SVR(),\n",
    "    # \"K-Nearest Neighbors Regressor (KNN)\": KNeighborsRegressor(), # 10.041602240167114\n",
    "    # \"Decision Tree Regressor\": DecisionTreeRegressor(random_state=42), # 12.862204876992518\n",
    "\n",
    "    # \"XGBoost Regressor 1\": XGBRegressor(n_estimators=100, random_state=42),# 8.80645474036935\n",
    "    # \"XGBoost Regressor\": XGBRegressor(**{k: v for k, v in xgb_params.items() if k not in ['early_stopping_rounds', 'eval_metric']}),\n",
    "    \n",
    "    # \"LightGBM Regressor\": LGBMRegressor(n_estimators=100, random_state=42),# 8.80233253326403\n",
    "\n",
    "    # \"CatBoost Regressor 1\": CatBoostRegressor(iterations=100, random_state=42, verbose=0),# 8.779514995823046\n",
    "    # \"CatBoost Regressor 2\": CatBoostRegressor(iterations=1000, random_state=42, verbose=0),# 8.750053736561881\n",
    "    # \"CatBoost Regressor 3\": CatBoostRegressor(iterations=2000, random_state=42, verbose=0),# 8.746984406439088\n",
    "    # \"CatBoost Regressor 4\": CatBoostRegressor(iterations=5000, random_state=42, verbose=0),#  8.74407813414281\n",
    "    \"CatBoost Regressor\": CatBoostRegressor(iterations=10000, random_state=42, verbose=0),\n",
    "\n",
    "    # \"ElasticNet Regression\": ElasticNet(alpha=1.0, l1_ratio=0.5),# 11.419489099367368\n",
    "    # \"Ridge Regression\": Ridge(alpha=1.0),# 9.945236728904232\n",
    "    # \"Lasso Regression\": Lasso(alpha=0.1),# 9.948718108336369\n",
    "    # \"Bayesian Ridge Regression\": BayesianRidge(),# 9.945236375344892\n",
    "\n",
    "    # TensorFlow / Keras models (use Input(...) as recommended)\n",
    "    # \"Neural Network (Dense) - 1 Layer\": tf.keras.Sequential([# 9.107451331633579\n",
    "    #     Input(shape=(num_features,)),\n",
    "    #     Dense(64, activation='relu'),\n",
    "    #     Dense(1)\n",
    "    # ]),\n",
    "    # \"Neural Network (Dense) - 2 Layers\": tf.keras.Sequential([# 9.0263789985335\n",
    "    #     Input(shape=(num_features,)),\n",
    "    #     Dense(64, activation='relu'),\n",
    "    #     Dense(64, activation='relu'),\n",
    "    #     Dense(1)\n",
    "    # ]),\n",
    "    # \"Neural Network (Deep) - 3 Layers\": tf.keras.Sequential([ # 9.015516714821777\n",
    "    #     Input(shape=(num_features,)),\n",
    "    #     Dense(128, activation='relu'),\n",
    "    #     Dense(128, activation='relu'),\n",
    "    #     Dense(128, activation='relu'),\n",
    "    #     Dense(1)\n",
    "    # ]),\n",
    "    # \"CNN for Regression\": tf.keras.Sequential([ # 9.129382497786011\n",
    "    #     Input(shape=(10, 1)),\n",
    "    #     Conv1D(32, kernel_size=3, activation='relu'),\n",
    "    #     MaxPooling1D(pool_size=2),\n",
    "    #     Flatten(),\n",
    "    #     Dense(64, activation='relu'),\n",
    "    #     Dense(1)\n",
    "    # ]),\n",
    "    # \"LSTM for Regression\": tf.keras.Sequential([ # 9.112482477086305\n",
    "    #     Input(shape=(10, 1)),\n",
    "    #     LSTM(64, return_sequences=False),\n",
    "    #     Dense(64, activation='relu'),\n",
    "    #     Dense(1)\n",
    "    # ]),\n",
    "    # \"GRU for Regression\": tf.keras.Sequential([ # 8.980764873623912\n",
    "    #     Input(shape=(10, 1)),\n",
    "    #     GRU(64, return_sequences=False),\n",
    "    #     Dense(64, activation='relu'),\n",
    "    #     Dense(1)\n",
    "    # ]),\n",
    "}\n",
    "\n",
    "# Note: commented Transformer / other models remain unchanged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Regressor RMSE: 8.741494909332976\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. Train models and evaluate them using RMSE\n",
    "best_rmse = float('inf')\n",
    "best_model_name = None\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Compile Keras models if necessary\n",
    "    if hasattr(model, 'compile') and callable(getattr(model, 'compile')):\n",
    "        try:\n",
    "            model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: could not compile {model_name}: {e}\")\n",
    "\n",
    "    # Train the model (handle both scikit-learn and Keras)\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "    except Exception as e:\n",
    "        print(f\"Error training {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Predict and evaluate\n",
    "    try:\n",
    "        y_pred = model.predict(X_valid)\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting with {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "    print(f\"{model_name} RMSE: {rmse}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # If the current RMSE is better (lower) than the previous best, update the best model\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_model_name = model_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CatBoost Regressor'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10. Choose the best model (Assume Random Forest performs the best)\n",
    "best_model = models[best_model_name]# [\"CatBoost Regressor\"]\n",
    "best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Train the final model on the full training data\n",
    "best_model.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Prepare the test data for predictions\n",
    "if 'id' in test_data.columns:  # Check if 'id' exists in test data before dropping it\n",
    "    X_test = test_data.drop(columns=['id'])  # 'id' is not a feature\n",
    "else:\n",
    "    X_test = test_data  # In case 'id' doesn't exist, just use the entire test data without 'id'\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Generate predictions\n",
    "test_predictions = best_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data['id'],  # Ensure 'id' is included in the submission\n",
    "    'exam_score': test_predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "# 15. Save the submission file\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14993753,
     "sourceId": 119082,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
