{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/competitions/playground-series-s6e1/data?select=train.csv\n",
    "\n",
    "# 1. Load the datasets\n",
    "folder_path_local = \"../input/playground-series-s6e1/\"\n",
    "folder_path_remote = \"https://kagglecsv.netlify.app/input/playground-series-s6e1/\"\n",
    "folder_path = folder_path_local if os.path.exists(folder_path_local) else folder_path_remote  # choose local if available, else remote\n",
    "train_data = pd.read_csv(folder_path + 'train.csv')\n",
    "test_data = pd.read_csv(folder_path + 'test.csv')\n",
    "print(\"Datasets loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Columns: Index(['id', 'age', 'gender', 'course', 'study_hours', 'class_attendance',\n",
      "       'internet_access', 'sleep_hours', 'sleep_quality', 'study_method',\n",
      "       'facility_rating', 'exam_difficulty', 'exam_score'],\n",
      "      dtype='object')\n",
      "Test Data Columns: Index(['id', 'age', 'gender', 'course', 'study_hours', 'class_attendance',\n",
      "       'internet_access', 'sleep_hours', 'sleep_quality', 'study_method',\n",
      "       'facility_rating', 'exam_difficulty'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 2. Check column names for both train and test data\n",
    "print(\"Train Data Columns:\", train_data.columns)\n",
    "print(\"Test Data Columns:\", test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: Index(['gender', 'course', 'internet_access', 'sleep_quality', 'study_method',\n",
      "       'facility_rating', 'exam_difficulty'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 3. Identify categorical columns (ignore 'id' column)\n",
    "categorical_columns = train_data.select_dtypes(include=['object']).columns\n",
    "categorical_columns = categorical_columns.drop('id', errors='ignore')  # Drop 'id' if it exists, otherwise ignore\n",
    "print(f\"Categorical columns: {categorical_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns converted: ['gender', 'course', 'internet_access', 'sleep_quality', 'study_method', 'facility_rating', 'exam_difficulty']\n"
     ]
    }
   ],
   "source": [
    "# 4. Convert categorical features to pandas 'category' dtype (preferred for tree models)\n",
    "categorical_columns = train_data.select_dtypes(include=['object']).columns.tolist()\n",
    "if 'id' in categorical_columns:\n",
    "    categorical_columns.remove('id')\n",
    "for col in categorical_columns:\n",
    "    train_data[col] = train_data[col].astype('category')\n",
    "    test_data[col] = test_data[col].astype('category')\n",
    "print(f\"Categorical columns converted: {categorical_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Split data into features (X) and target (y)\n",
    "if 'id' in train_data.columns:  # Check if 'id' exists before dropping it\n",
    "    X = train_data.drop(columns=['id', 'exam_score'])  # Drop 'id' and 'exam_score' columns\n",
    "else:\n",
    "    X = train_data.drop(columns=['exam_score'])  # Only drop 'exam_score' if 'id' is not present\n",
    "y = train_data['exam_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed numeric columns: ['age', 'study_hours', 'class_attendance', 'sleep_hours']\n"
     ]
    }
   ],
   "source": [
    "# 6. Simple imputation for numeric features (no scaling for tree models)\n",
    "from sklearn.impute import SimpleImputer\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X[num_cols] = imputer.fit_transform(X[num_cols])\n",
    "# Prepare a version of the test features for later\n",
    "if 'id' in test_data.columns:\n",
    "    X_test = test_data.drop(columns=['id']).copy()\n",
    "else:\n",
    "    X_test = test_data.copy()\n",
    "X_test[num_cols] = imputer.transform(X_test[num_cols])\n",
    "print('Imputed numeric columns:', num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Train-test split (for evaluation purposes)\n",
    "# NOTE: the earlier pipeline removed scaling; the actual split is performed later using the imputed DataFrame `X`\n",
    "# (Old split referencing `X_scaled_df` has been removed to avoid NameError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2026-01-01T00:41:09.667621Z",
     "shell.execute_reply": "2026-01-01T00:41:09.666559Z",
     "shell.execute_reply.started": "2026-01-01T00:29:45.489881Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features to pass to models: ['gender', 'course', 'internet_access', 'sleep_quality', 'study_method', 'facility_rating', 'exam_difficulty']\n"
     ]
    }
   ],
   "source": [
    "# Models: fast, well-performing tree ensembles with early stopping capability\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "models = {\n",
    "    'LightGBM': LGBMRegressor(n_estimators=1000, learning_rate=0.03, max_depth=7, random_state=42),\n",
    "    # 'CatBoost': CatBoostRegressor(iterations=1000, learning_rate=0.03, depth=6, random_state=42, verbose=0),\n",
    "    # 'XGBoost': XGBRegressor(n_estimators=1000, learning_rate=0.03, max_depth=6, random_state=42, tree_method='hist', verbosity=0)\n",
    "}\n",
    "\n",
    "# Determine categorical feature names (for LightGBM/CatBoost)\n",
    "categorical_features = [col for col in X.columns if str(X[col].dtype) == 'category']\n",
    "print('Categorical features to pass to models:', categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 602\n",
      "[LightGBM] [Info] Number of data points in the train set: 504000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 62.482335\n",
      "LightGBM MAE: 6.98679511074426\n",
      "\n",
      "\n",
      "Best model: LightGBM with MAE: 6.98679511074426\n"
     ]
    }
   ],
   "source": [
    "# 9. Train models and evaluate them using MAE with early stopping on a validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "trained_models = {}\n",
    "best_mae = float('inf')\n",
    "best_model_name = None\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    try:\n",
    "        if name == 'LightGBM':\n",
    "            # Some lightgbm versions don't accept early_stopping_rounds in sklearn API; omit it for compatibility\n",
    "            try:\n",
    "                model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], eval_metric='l1',\n",
    "                          categorical_feature=categorical_features, verbose=False)\n",
    "            except TypeError:\n",
    "                model.fit(X_train, y_train)\n",
    "        elif name == 'CatBoost':\n",
    "            # CatBoost expects cat_features list when pandas categorical dtypes are present\n",
    "            try:\n",
    "                model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=categorical_features,\n",
    "                          use_best_model=True, verbose=False)\n",
    "            except TypeError:\n",
    "                model.fit(X_train, y_train)\n",
    "        elif name == 'XGBoost':\n",
    "            # XGBoost sklearn wrapper may not accept eval_metric in some versions; try with early stopping, else fallback\n",
    "            try:\n",
    "                model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds=50, verbose=False)\n",
    "            except TypeError:\n",
    "                try:\n",
    "                    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)\n",
    "                except TypeError:\n",
    "                    model.fit(X_train, y_train)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "    except Exception as e:\n",
    "        print(f\"Error training {name}:\", e)\n",
    "        continue\n",
    "\n",
    "    y_pred = model.predict(X_valid)\n",
    "    mae = mean_absolute_error(y_valid, y_pred)\n",
    "    print(f\"{name} MAE: {mae}\")\n",
    "    trained_models[name] = model\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        best_model_name = name\n",
    "    print('\\n')\n",
    "\n",
    "print('Best model:', best_model_name, 'with MAE:', best_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LightGBM'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10. Select best model object\n",
    "if not trained_models:\n",
    "    raise RuntimeError('No models were successfully trained. Check training logs above for errors.')\n",
    "if best_model_name is None:\n",
    "    # If best_model_name wasn't set (e.g. training skipped/failed for all), pick the first trained model\n",
    "    best_model_name = list(trained_models.keys())[0]\n",
    "    print('Warning: best_model_name was None; defaulting to', best_model_name)\n",
    "best_model = trained_models[best_model_name]\n",
    "best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining best model on full data: LightGBM\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 602\n",
      "[LightGBM] [Info] Number of data points in the train set: 630000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 62.506672\n"
     ]
    }
   ],
   "source": [
    "# 11. Retrain best model on full training data (X, y)\n",
    "print('Retraining best model on full data:', best_model_name)\n",
    "if best_model_name == 'LightGBM':\n",
    "    best_model.set_params(n_estimators=2000)\n",
    "    # Some lightgbm sklearn wrappers don't accept 'verbose' in fit(); try safely\n",
    "    try:\n",
    "        best_model.fit(X, y, categorical_feature=categorical_features, verbose=False)\n",
    "    except TypeError:\n",
    "        try:\n",
    "            best_model.fit(X, y, categorical_feature=categorical_features)\n",
    "        except TypeError:\n",
    "            best_model.fit(X, y)\n",
    "elif best_model_name == 'CatBoost':\n",
    "    best_model.set_params(iterations=2000)\n",
    "    try:\n",
    "        best_model.fit(X, y, cat_features=categorical_features, verbose=False)\n",
    "    except TypeError:\n",
    "        best_model.fit(X, y)\n",
    "elif best_model_name == 'XGBoost':\n",
    "    best_model.set_params(n_estimators=2000)\n",
    "    try:\n",
    "        best_model.fit(X, y, verbose=False)\n",
    "    except TypeError:\n",
    "        best_model.fit(X, y)\n",
    "else:\n",
    "    best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270000, 11)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12. Ensure categorical dtypes preserved in test set\n",
    "for col in categorical_features:\n",
    "    if col in X_test.columns:\n",
    "        X_test[col] = X_test[col].astype('category')\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Generate predictions using ensemble of trained models (average)\n",
    "preds = []\n",
    "for name, model in trained_models.items():\n",
    "    try:\n",
    "        preds.append(model.predict(X_test))\n",
    "    except Exception as e:\n",
    "        print(f'Error predicting with {name}:', e)\n",
    "import numpy as np\n",
    "if preds:\n",
    "    ensemble_preds = np.mean(preds, axis=0)\n",
    "else:\n",
    "    ensemble_preds = best_model.predict(X_test)\n",
    "\n",
    "test_predictions = ensemble_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "exam_score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a8662f27-648b-4aba-ba3f-c0acef9567b2",
       "rows": [
        [
         "0",
         "630000",
         "71.74894867003428"
        ],
        [
         "1",
         "630001",
         "69.8797229172218"
        ],
        [
         "2",
         "630002",
         "87.72186734640478"
        ],
        [
         "3",
         "630003",
         "56.19557860313831"
        ],
        [
         "4",
         "630004",
         "46.7436146131388"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>exam_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630000</td>\n",
       "      <td>71.748949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>630001</td>\n",
       "      <td>69.879723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>630002</td>\n",
       "      <td>87.721867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>630003</td>\n",
       "      <td>56.195579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>630004</td>\n",
       "      <td>46.743615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  exam_score\n",
       "0  630000   71.748949\n",
       "1  630001   69.879723\n",
       "2  630002   87.721867\n",
       "3  630003   56.195579\n",
       "4  630004   46.743615"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 14. Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'exam_score': test_predictions\n",
    "})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "# 15. Save the submission file\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print('Submission file created successfully!')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14993753,
     "sourceId": 119082,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
